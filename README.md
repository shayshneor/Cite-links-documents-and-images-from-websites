# Cite-links-documents-and-images-from-websites
It is a Python tool that scans a given website, finds all the paths and links on the page, and automatically downloads relevant files such as images and PDFs to a designated folder on your computer.

ğŸš€ Main capabilities
ğŸ” Scan paths from  tags on the main page of the site

ğŸŒ Retrieve all absolute URLs from the page

ğŸ“¥ Automatically download image files (.jpg, .png, etc.) and PDF

ğŸ—‚ Create a download folder on your desktop

ğŸ“› Handle errors and access invalid links

ğŸ§± Possible uses
Collecting initial information (reconnaissance) for analysts and cyber experts

Downloading assets from websites for testing

Analyzing the link structure of websites

Practice web scraping

ğŸ“Œ Notes
The tool only crawls the main page given in the URL (does not perform deep crawling).

Does not currently support authentication, JavaScript, or dynamic content.

Do not use the tool to crawl websites without authorization â€“ remain legal and ethical.
